{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "\n",
    "# inside these folders there are multiple text files\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "texts = [] # texts from all the text files\n",
    "class_labels = [] # labels\n",
    "\n",
    "for c in classes:\n",
    "    for f in glob.glob(os.path.join('bbc', c, '*.txt')):\n",
    "        texts.append(open(f).read())\n",
    "        class_labels.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "\n",
      "business\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(len(class_labels))\n",
    "print(texts[0])\n",
    "print(class_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have 5 classes ['business', 'entertainment', 'politics', 'sport', 'tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Seed and Data Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "random.seed(10)\n",
    "numpy.random.seed(10)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "z = list(zip(texts, class_labels))\n",
    "random.shuffle(z)\n",
    "\n",
    "texts, class_labels = [a[0] for a in z], [a[1] for a in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sport',\n",
       " 'entertainment',\n",
       " 'sport',\n",
       " 'business',\n",
       " 'sport',\n",
       " 'politics',\n",
       " 'business',\n",
       " 'sport',\n",
       " 'tech',\n",
       " 'tech',\n",
       " 'business',\n",
       " 'entertainment',\n",
       " 'politics',\n",
       " 'tech',\n",
       " 'tech',\n",
       " 'entertainment',\n",
       " 'business',\n",
       " 'tech',\n",
       " 'sport',\n",
       " 'business']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'politics': 417,\n",
       "         'business': 510,\n",
       "         'entertainment': 386,\n",
       "         'tech': 401,\n",
       "         'sport': 511})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', max_length = 512, padding_side = 'right')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(texts[0], add_special_tokens=True, max_length = 512, pad_to_max_length = True)).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2829,  7879, 22889,  2819,  2006,  3088,  4440,  7306,  5146,\n",
      "          2829,  2038,  4716,  7938,  1005,  1055,  5221, 17137,  3723,  4665,\n",
      "          2004,  2002,  2441,  1037,  2733,  1011,  2146,  3942,  2000,  3088,\n",
      "          1012,  2720,  2829,  1005,  1055,  4440,  2003,  2881,  2000, 12944,\n",
      "          2129,  1996,  2866,  4122,  2000,  2191,  3088,  1005,  1055,  3471,\n",
      "          1037,  9470,  1997,  2049,  3472,  9650,  1997,  1996,  1043,  2620,\n",
      "          2023,  2095,  1012,  2002,  2097,  2156,  2019,  9820,  1013,  8387,\n",
      "         18504,  1999, 11959,  1998,  1037,  2308,  1005,  1055,  4923,  2586,\n",
      "          1999, 16274,  2077,  3242,  2075,  1037,  3116,  1997,  1996,  3222,\n",
      "          2005,  3088,  1999,  4880,  2237,  1012,  2012, 22889, 18163,  1999,\n",
      "          6583,  3217,  5638,  2006,  9317,  1010,  2002,  2056,  2495,  3791,\n",
      "          2018,  2000,  2022, 26176,  1012,  4092,  2648,  1996,  4386,  3078,\n",
      "          2082,  1010,  2720,  2829,  2056,  1024,  1000,  2009,  2003,  3432,\n",
      "          2025, 11701,  1999,  1996,  2715,  2287,  2005,  1996,  2717,  1997,\n",
      "          1996,  2088,  2000,  3233,  2011,  1998,  2031,  5606,  1997,  8817,\n",
      "          1997,  2336,  2025,  2893,  1996,  3382,  2012,  2495,  1012,  1000,\n",
      "          2002,  4197,  2000,  2248,  3488,  2000, 15697,  1002,  2184, 24700,\n",
      "          2005,  2495,  1999,  3088,  2058,  1996,  2279,  5476,  1012,  1996,\n",
      "          2082,  2003,  2006,  1996,  3341,  1997, 11382,  5677,  2050,  1010,\n",
      "          2073,  5385,  1010,  2199,  2444,  2411,  1999, 23326,  2081,  1997,\n",
      "          8494,  1010, 15121,  3384,  1998, 19747,  1012,  2720,  2829,  1005,\n",
      "          1055, 14895,  2015,  2360,  2002,  4122,  2000,  2424,  2041,  2062,\n",
      "          2055,  1996, 20428,  2231,  1005,  1055,  2495,  6043,  1010,  2029,\n",
      "          2443, 10449,  2489,  3078,  2495,  1999,  2220,  2494,  1012,  1996,\n",
      "          7306,  2038,  2525, 11521, 10340,  2005,  1037,  1043,  2620,  4681,\n",
      "          7427,  2029,  2002,  2038, 28834,  2000,  1996,  5832,  2933,  2109,\n",
      "          2011,  1996,  2142,  2163,  2000, 14591,  2885,  2044,  2088,  2162,\n",
      "          2048,  1012,  1996,  4440,  4076,  4447,  1997,  1999, 22158,  2090,\n",
      "          2720,  2829,  1998,  4116, 10503,  6851,  1999,  1037,  2047,  2338,\n",
      "          1012,  4603,  3003,  2745,  4922,  2003,  3517,  2000, 15126,  2006,\n",
      "          2216,  4311,  2012,  3539,  2704,  1005,  1055,  3980,  2012, 14840,\n",
      "         13938,  2102,  2006,  9317,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need attention masks\n",
    "\n",
    "encoded = tokenizer.encode_plus(texts[0], add_special_tokens=True, max_length = 512, pad_to_max_length = True,\n",
    "                                return_token_type_ids = False,\n",
    "                                return_attention_mask = True)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained BERT for sequence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "bertclassifier, li = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 5,\n",
    "                                                                   output_loading_info=True) # as we have 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bertclassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last linear layer has 5 out_features. `(classifier): Linear(in_features=768, out_features=5, bias=True)`\n",
    "\n",
    "We can just add a softmax after that and do our regular classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missing_keys': ['classifier.weight', 'classifier.bias'], 'unexpected_keys': ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias'], 'error_msgs': []}\n"
     ]
    }
   ],
   "source": [
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bert.embeddings.word_embeddings.weight\n",
      "1 bert.embeddings.position_embeddings.weight\n",
      "2 bert.embeddings.token_type_embeddings.weight\n",
      "3 bert.embeddings.LayerNorm.weight\n",
      "4 bert.embeddings.LayerNorm.bias\n",
      "5 bert.encoder.layer.0.attention.self.query.weight\n",
      "6 bert.encoder.layer.0.attention.self.query.bias\n",
      "7 bert.encoder.layer.0.attention.self.key.weight\n",
      "8 bert.encoder.layer.0.attention.self.key.bias\n",
      "9 bert.encoder.layer.0.attention.self.value.weight\n",
      "10 bert.encoder.layer.0.attention.self.value.bias\n",
      "11 bert.encoder.layer.0.attention.output.dense.weight\n",
      "12 bert.encoder.layer.0.attention.output.dense.bias\n",
      "13 bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "14 bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "15 bert.encoder.layer.0.intermediate.dense.weight\n",
      "16 bert.encoder.layer.0.intermediate.dense.bias\n",
      "17 bert.encoder.layer.0.output.dense.weight\n",
      "18 bert.encoder.layer.0.output.dense.bias\n",
      "19 bert.encoder.layer.0.output.LayerNorm.weight\n",
      "20 bert.encoder.layer.0.output.LayerNorm.bias\n",
      "21 bert.encoder.layer.1.attention.self.query.weight\n",
      "22 bert.encoder.layer.1.attention.self.query.bias\n",
      "23 bert.encoder.layer.1.attention.self.key.weight\n",
      "24 bert.encoder.layer.1.attention.self.key.bias\n",
      "25 bert.encoder.layer.1.attention.self.value.weight\n",
      "26 bert.encoder.layer.1.attention.self.value.bias\n",
      "27 bert.encoder.layer.1.attention.output.dense.weight\n",
      "28 bert.encoder.layer.1.attention.output.dense.bias\n",
      "29 bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "30 bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "31 bert.encoder.layer.1.intermediate.dense.weight\n",
      "32 bert.encoder.layer.1.intermediate.dense.bias\n",
      "33 bert.encoder.layer.1.output.dense.weight\n",
      "34 bert.encoder.layer.1.output.dense.bias\n",
      "35 bert.encoder.layer.1.output.LayerNorm.weight\n",
      "36 bert.encoder.layer.1.output.LayerNorm.bias\n",
      "37 bert.encoder.layer.2.attention.self.query.weight\n",
      "38 bert.encoder.layer.2.attention.self.query.bias\n",
      "39 bert.encoder.layer.2.attention.self.key.weight\n",
      "40 bert.encoder.layer.2.attention.self.key.bias\n",
      "41 bert.encoder.layer.2.attention.self.value.weight\n",
      "42 bert.encoder.layer.2.attention.self.value.bias\n",
      "43 bert.encoder.layer.2.attention.output.dense.weight\n",
      "44 bert.encoder.layer.2.attention.output.dense.bias\n",
      "45 bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "46 bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "47 bert.encoder.layer.2.intermediate.dense.weight\n",
      "48 bert.encoder.layer.2.intermediate.dense.bias\n",
      "49 bert.encoder.layer.2.output.dense.weight\n",
      "50 bert.encoder.layer.2.output.dense.bias\n",
      "51 bert.encoder.layer.2.output.LayerNorm.weight\n",
      "52 bert.encoder.layer.2.output.LayerNorm.bias\n",
      "53 bert.encoder.layer.3.attention.self.query.weight\n",
      "54 bert.encoder.layer.3.attention.self.query.bias\n",
      "55 bert.encoder.layer.3.attention.self.key.weight\n",
      "56 bert.encoder.layer.3.attention.self.key.bias\n",
      "57 bert.encoder.layer.3.attention.self.value.weight\n",
      "58 bert.encoder.layer.3.attention.self.value.bias\n",
      "59 bert.encoder.layer.3.attention.output.dense.weight\n",
      "60 bert.encoder.layer.3.attention.output.dense.bias\n",
      "61 bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "62 bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "63 bert.encoder.layer.3.intermediate.dense.weight\n",
      "64 bert.encoder.layer.3.intermediate.dense.bias\n",
      "65 bert.encoder.layer.3.output.dense.weight\n",
      "66 bert.encoder.layer.3.output.dense.bias\n",
      "67 bert.encoder.layer.3.output.LayerNorm.weight\n",
      "68 bert.encoder.layer.3.output.LayerNorm.bias\n",
      "69 bert.encoder.layer.4.attention.self.query.weight\n",
      "70 bert.encoder.layer.4.attention.self.query.bias\n",
      "71 bert.encoder.layer.4.attention.self.key.weight\n",
      "72 bert.encoder.layer.4.attention.self.key.bias\n",
      "73 bert.encoder.layer.4.attention.self.value.weight\n",
      "74 bert.encoder.layer.4.attention.self.value.bias\n",
      "75 bert.encoder.layer.4.attention.output.dense.weight\n",
      "76 bert.encoder.layer.4.attention.output.dense.bias\n",
      "77 bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "78 bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "79 bert.encoder.layer.4.intermediate.dense.weight\n",
      "80 bert.encoder.layer.4.intermediate.dense.bias\n",
      "81 bert.encoder.layer.4.output.dense.weight\n",
      "82 bert.encoder.layer.4.output.dense.bias\n",
      "83 bert.encoder.layer.4.output.LayerNorm.weight\n",
      "84 bert.encoder.layer.4.output.LayerNorm.bias\n",
      "85 bert.encoder.layer.5.attention.self.query.weight\n",
      "86 bert.encoder.layer.5.attention.self.query.bias\n",
      "87 bert.encoder.layer.5.attention.self.key.weight\n",
      "88 bert.encoder.layer.5.attention.self.key.bias\n",
      "89 bert.encoder.layer.5.attention.self.value.weight\n",
      "90 bert.encoder.layer.5.attention.self.value.bias\n",
      "91 bert.encoder.layer.5.attention.output.dense.weight\n",
      "92 bert.encoder.layer.5.attention.output.dense.bias\n",
      "93 bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "94 bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "95 bert.encoder.layer.5.intermediate.dense.weight\n",
      "96 bert.encoder.layer.5.intermediate.dense.bias\n",
      "97 bert.encoder.layer.5.output.dense.weight\n",
      "98 bert.encoder.layer.5.output.dense.bias\n",
      "99 bert.encoder.layer.5.output.LayerNorm.weight\n",
      "100 bert.encoder.layer.5.output.LayerNorm.bias\n",
      "101 bert.encoder.layer.6.attention.self.query.weight\n",
      "102 bert.encoder.layer.6.attention.self.query.bias\n",
      "103 bert.encoder.layer.6.attention.self.key.weight\n",
      "104 bert.encoder.layer.6.attention.self.key.bias\n",
      "105 bert.encoder.layer.6.attention.self.value.weight\n",
      "106 bert.encoder.layer.6.attention.self.value.bias\n",
      "107 bert.encoder.layer.6.attention.output.dense.weight\n",
      "108 bert.encoder.layer.6.attention.output.dense.bias\n",
      "109 bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "110 bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "111 bert.encoder.layer.6.intermediate.dense.weight\n",
      "112 bert.encoder.layer.6.intermediate.dense.bias\n",
      "113 bert.encoder.layer.6.output.dense.weight\n",
      "114 bert.encoder.layer.6.output.dense.bias\n",
      "115 bert.encoder.layer.6.output.LayerNorm.weight\n",
      "116 bert.encoder.layer.6.output.LayerNorm.bias\n",
      "117 bert.encoder.layer.7.attention.self.query.weight\n",
      "118 bert.encoder.layer.7.attention.self.query.bias\n",
      "119 bert.encoder.layer.7.attention.self.key.weight\n",
      "120 bert.encoder.layer.7.attention.self.key.bias\n",
      "121 bert.encoder.layer.7.attention.self.value.weight\n",
      "122 bert.encoder.layer.7.attention.self.value.bias\n",
      "123 bert.encoder.layer.7.attention.output.dense.weight\n",
      "124 bert.encoder.layer.7.attention.output.dense.bias\n",
      "125 bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "126 bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "127 bert.encoder.layer.7.intermediate.dense.weight\n",
      "128 bert.encoder.layer.7.intermediate.dense.bias\n",
      "129 bert.encoder.layer.7.output.dense.weight\n",
      "130 bert.encoder.layer.7.output.dense.bias\n",
      "131 bert.encoder.layer.7.output.LayerNorm.weight\n",
      "132 bert.encoder.layer.7.output.LayerNorm.bias\n",
      "133 bert.encoder.layer.8.attention.self.query.weight\n",
      "134 bert.encoder.layer.8.attention.self.query.bias\n",
      "135 bert.encoder.layer.8.attention.self.key.weight\n",
      "136 bert.encoder.layer.8.attention.self.key.bias\n",
      "137 bert.encoder.layer.8.attention.self.value.weight\n",
      "138 bert.encoder.layer.8.attention.self.value.bias\n",
      "139 bert.encoder.layer.8.attention.output.dense.weight\n",
      "140 bert.encoder.layer.8.attention.output.dense.bias\n",
      "141 bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "142 bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "143 bert.encoder.layer.8.intermediate.dense.weight\n",
      "144 bert.encoder.layer.8.intermediate.dense.bias\n",
      "145 bert.encoder.layer.8.output.dense.weight\n",
      "146 bert.encoder.layer.8.output.dense.bias\n",
      "147 bert.encoder.layer.8.output.LayerNorm.weight\n",
      "148 bert.encoder.layer.8.output.LayerNorm.bias\n",
      "149 bert.encoder.layer.9.attention.self.query.weight\n",
      "150 bert.encoder.layer.9.attention.self.query.bias\n",
      "151 bert.encoder.layer.9.attention.self.key.weight\n",
      "152 bert.encoder.layer.9.attention.self.key.bias\n",
      "153 bert.encoder.layer.9.attention.self.value.weight\n",
      "154 bert.encoder.layer.9.attention.self.value.bias\n",
      "155 bert.encoder.layer.9.attention.output.dense.weight\n",
      "156 bert.encoder.layer.9.attention.output.dense.bias\n",
      "157 bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "158 bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "159 bert.encoder.layer.9.intermediate.dense.weight\n",
      "160 bert.encoder.layer.9.intermediate.dense.bias\n",
      "161 bert.encoder.layer.9.output.dense.weight\n",
      "162 bert.encoder.layer.9.output.dense.bias\n",
      "163 bert.encoder.layer.9.output.LayerNorm.weight\n",
      "164 bert.encoder.layer.9.output.LayerNorm.bias\n",
      "165 bert.encoder.layer.10.attention.self.query.weight\n",
      "166 bert.encoder.layer.10.attention.self.query.bias\n",
      "167 bert.encoder.layer.10.attention.self.key.weight\n",
      "168 bert.encoder.layer.10.attention.self.key.bias\n",
      "169 bert.encoder.layer.10.attention.self.value.weight\n",
      "170 bert.encoder.layer.10.attention.self.value.bias\n",
      "171 bert.encoder.layer.10.attention.output.dense.weight\n",
      "172 bert.encoder.layer.10.attention.output.dense.bias\n",
      "173 bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "174 bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "175 bert.encoder.layer.10.intermediate.dense.weight\n",
      "176 bert.encoder.layer.10.intermediate.dense.bias\n",
      "177 bert.encoder.layer.10.output.dense.weight\n",
      "178 bert.encoder.layer.10.output.dense.bias\n",
      "179 bert.encoder.layer.10.output.LayerNorm.weight\n",
      "180 bert.encoder.layer.10.output.LayerNorm.bias\n",
      "181 bert.encoder.layer.11.attention.self.query.weight\n",
      "182 bert.encoder.layer.11.attention.self.query.bias\n",
      "183 bert.encoder.layer.11.attention.self.key.weight\n",
      "184 bert.encoder.layer.11.attention.self.key.bias\n",
      "185 bert.encoder.layer.11.attention.self.value.weight\n",
      "186 bert.encoder.layer.11.attention.self.value.bias\n",
      "187 bert.encoder.layer.11.attention.output.dense.weight\n",
      "188 bert.encoder.layer.11.attention.output.dense.bias\n",
      "189 bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "190 bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "191 bert.encoder.layer.11.intermediate.dense.weight\n",
      "192 bert.encoder.layer.11.intermediate.dense.bias\n",
      "193 bert.encoder.layer.11.output.dense.weight\n",
      "194 bert.encoder.layer.11.output.dense.bias\n",
      "195 bert.encoder.layer.11.output.LayerNorm.weight\n",
      "196 bert.encoder.layer.11.output.LayerNorm.bias\n",
      "197 bert.pooler.dense.weight\n",
      "198 bert.pooler.dense.bias\n",
      "199 classifier.weight\n",
      "200 classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for i, name_param in enumerate(bertclassifier.named_parameters()):\n",
    "    print(i, name_param[0])\n",
    "    # we freeze first 21 layers (first encoder)\n",
    "    if i <= 20:\n",
    "        name_param[1].requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1064,  0.1848,  0.0699,  0.0150, -0.2364]],\n",
       "        grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertclassifier.eval()\n",
    "bertclassifier(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# checking the frozen layers \n",
    "print(list(bertclassifier.parameters())[20].requires_grad)\n",
    "\n",
    "# trainable layer\n",
    "print(list(bertclassifier.parameters())[-100].requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# create our dataset\n",
    "\n",
    "class BBCArticleDataset(Dataset):\n",
    "    def __init__(self, texts, class_labels, class_id, tokenizer, train = True, train_split = 0.8): # pass the text and the labels, class_id : dict -> ohe\n",
    "        \n",
    "        self.train = train\n",
    "        \n",
    "        assert(len(class_labels) == len(texts))\n",
    "        assert(type(class_id) == dict)\n",
    "        \n",
    "        if self.train:\n",
    "            self.texts = texts[: int(len(texts)*train_split) ]\n",
    "            self.class_labels = class_labels[: int(len(texts)*train_split) ]\n",
    "        else:\n",
    "            self.texts = texts[ int(len(texts)*train_split): ]\n",
    "            self.class_labels = class_labels[ int(len(texts)*train_split): ]\n",
    "        self.class_id = class_id\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.class_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        encoded = tokenizer.encode_plus(self.texts[idx], add_special_tokens=True, max_length = 512, pad_to_max_length = True,\n",
    "                                return_token_type_ids = False,\n",
    "                                return_attention_mask = True)  # Batch size 1\n",
    "            \n",
    "        # text to tokens\n",
    "        token = torch.tensor(encoded['input_ids']) #.unsqueeze(0)\n",
    "        mask = torch.tensor(encoded['attention_mask'])\n",
    "        # ohe label\n",
    "        ohe = torch.tensor(class_id[ class_labels[idx] ])\n",
    "        \n",
    "        if self.train:\n",
    "            return token, mask, ohe\n",
    "        else:\n",
    "            return token, mask, ohe # no mask needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = {'business' : 0, 'entertainment' : 1,\n",
    "           'politics' : 2, 'sport' : 3,\n",
    "           'tech' : 4}\n",
    "\n",
    "bbc_dataset_train = BBCArticleDataset(texts, class_labels, class_id, tokenizer)\n",
    "bbc_dataset_test = BBCArticleDataset(texts, class_labels, class_id, tokenizer, train = False)\n",
    "\n",
    "bbc_dataloader_train = DataLoader(bbc_dataset_train, batch_size=2, shuffle=True)\n",
    "bbc_dataloader_test = DataLoader(bbc_dataset_test, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(bbc_dataset_train[0][0].shape)\n",
    "print(bbc_dataset_train[0][1].shape)\n",
    "print(bbc_dataset_train[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "1\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "2\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "3\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "4\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "5\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "6\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "7\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "8\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "9\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n",
      "10\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# let's look at few examples\n",
    "\n",
    "for i_batch, sample_batch in enumerate(bbc_dataloader_train):\n",
    "    print(i_batch)\n",
    "    X, mask_X, y = sample_batch\n",
    "    print(X.shape)\n",
    "    print(mask_X.shape)\n",
    "    print(y.shape)\n",
    "    if i_batch == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # cuda for gpu acceleration\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = transformers.AdamW(bertclassifier.parameters(), lr = 1e-5)\n",
    "\n",
    "\n",
    "bertclassifier.to(device) # taking the model to gpu if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31b187b295540b49b22bd1dc1bf67b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805e52e343ed413bbd26ca77d56ab0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.34490313563454017\n",
      "acc: 0.902247191011236\n",
      "f1: 0.9000000000000001\n",
      "test acc: 0.9898876404494382\n",
      "test f1: 0.9900749063670413\n",
      "epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b37d2be0304615a7b925ba8e0e98ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.06370931147189622\n",
      "acc: 0.9870786516853932\n",
      "f1: 0.9880149812734081\n",
      "test acc: 0.9938202247191011\n",
      "test f1: 0.9941947565543071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training epochs\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "train_metrics = {'acc': [], 'f1': []}\n",
    "test_metrics = {'acc': [], 'f1': []}\n",
    "\n",
    "# progress bar\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "for e in tqdm_notebook(range(epochs)):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_f1 = 0.0\n",
    "    batch_cnt = 0\n",
    "    \n",
    "    bertclassifier.train()\n",
    "    \n",
    "    print(f'epoch: {e+1}')\n",
    "    \n",
    "    for i_batch, (X, X_mask, y) in tqdm_notebook(enumerate(bbc_dataloader_train)):\n",
    "        X = X.to(device)\n",
    "        X_mask = X_mask.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss, y_pred = bertclassifier(X, attention_mask = X_mask, labels = y)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(bertclassifier.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = torch.argmax(y_pred, dim = -1)\n",
    "        \n",
    "        # update metrics\n",
    "        train_acc += accuracy_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "        train_f1 += f1_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy(), average = 'weighted')\n",
    "        batch_cnt += 1\n",
    "    \n",
    "    print(f'train loss: {train_loss/batch_cnt}')\n",
    "    print(f'acc: {train_acc/batch_cnt}')\n",
    "    print(f'f1: {train_f1/batch_cnt}')\n",
    "    train_losses.append(train_loss/batch_cnt)\n",
    "    train_metrics['acc'].append(train_acc/batch_cnt)\n",
    "    train_metrics['f1'].append(train_f1/batch_cnt)\n",
    "        \n",
    "        \n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    test_f1 = 0.0\n",
    "    batch_cnt = 0\n",
    "    \n",
    "    bertclassifier.eval()\n",
    "    with torch.no_grad():\n",
    "        for i_batch, (X, X_mask, y) in enumerate(bbc_dataloader_train):\n",
    "            X = X.to(device)\n",
    "            X_mask = X_mask.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = bertclassifier(X, attention_mask = X_mask, labels = y)[1] # in eval model we get the softmax output so, don't need to index\n",
    "\n",
    "            \n",
    "            y_pred = torch.argmax(y_pred, dim = -1)\n",
    "\n",
    "            # update metrics\n",
    "            test_acc += accuracy_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "            test_f1 += f1_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy(), average = 'weighted')\n",
    "            batch_cnt += 1\n",
    "            \n",
    "    test_metrics['acc'].append(test_acc/batch_cnt)\n",
    "    test_metrics['f1'].append(test_f1/batch_cnt)\n",
    "    print(f'test acc: {test_acc/batch_cnt}')\n",
    "    print(f'test f1: {test_f1/batch_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the result\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_metrics['acc'], 'kx')\n",
    "plt.plot(train_metrics['f1'], 'r')\n",
    "plt.legend(['train acc', 'train f1'])\n",
    "plt.show()\n",
    "plt.plot(test_metrics['acc'], 'bx')\n",
    "plt.plot(test_metrics['f1'], 'y')\n",
    "plt.legend(['test acc', 'test f1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
